{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "np.random.shuffle(data) #to avoid any prepattern , or porder just making ssure \n",
    "\n",
    "print(m,n)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of images = m = 42k\n",
    "\n",
    "we wanted the data in array form \n",
    "\n",
    "we  need to separate the label column and make n=764\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0:int(0.8*m), :]   #80% of the data is for training\n",
    "\n",
    "val_data = data[int(0.8*m):m, :]      #20% of the data is for validation\n",
    "\n",
    "X_train=train_data[:,1:].T       #taking all the rows and all the columns except the first one\n",
    "Y_train=train_data[:,0]           #taking all the rows and only the first column: puotput\n",
    "\n",
    "X_val=val_data[:,1:].T\n",
    "Y_val=val_data[:,0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 33600) (33600,) (784, 8400) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation of pixel values: \n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_val=X_val/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def  one_hot_converter(Y):\n",
    "    \n",
    "    one_hot_Y=np.zeros((Y.size, Y.max()+1))  #33600 x 10 matrix od zeroes \n",
    "    one_hot_Y[np.arange(Y.size),Y]=1            #putting one where y occures \n",
    "    one_hot_Y=one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "one_hot_converter(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  W1 = np.random.rand(10, 784) - 0.5\n",
    "  B1 = np.random.rand(10, 1) - 0.5\n",
    "  W2 = np.random.rand(10, 10) - 0.5\n",
    "  B2 = np.random.rand(10, 1) - 0.5\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def ReLU(X):\n",
    "  return np.maximum(X, 0)      #if x is greater than 0 then return x else return 0\n",
    "\n",
    "def softmax_calculator(Z):\n",
    "  return np.exp(Z) / sum(np.exp(Z))   \n",
    "\n",
    "def forward_propagation(W1, B1, W2, B2, X):\n",
    "  Z1 = W1.dot(X) + B1        #hidden layer 1          \n",
    "  A1 = ReLU(Z1)             #activation function\n",
    "  Z2 = W2.dot(A1) + B2      #hidden layer 2\n",
    "  A2 = softmax_calculator(Z2)   \n",
    "  return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_converter(Y):\n",
    "  one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "  one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "  return one_hot_Y.T\n",
    "\n",
    "def backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y):\n",
    "  one_hot_Y = one_hot_converter(Y)\n",
    "  dZ2 = A2 - one_hot_Y\n",
    "  dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "  dB2 = 1 / m * np.sum(dZ2)\n",
    "  dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "  dW1 = 1 / m * dZ1.dot(X.T)\n",
    "  dB1 = 1 / m * np.sum(dZ1)\n",
    "  return dW1, dB1, dW2, dB2\n",
    "\n",
    "def update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, learning_rate):\n",
    "  W1 = W1 - learning_rate * dW1\n",
    "  B1 = B1 - learning_rate * dB1\n",
    "  W2 = W2 - learning_rate * dW2\n",
    "  B2 = B2 - learning_rate * dB2\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "  W1, B1, W2, B2 = initialize_parameters()\n",
    "\n",
    "  for i in range(iterations):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(W1, B1, W2, B2, X)\n",
    "    dW1, dB1, dW2, dB2 = backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y)\n",
    "    W1, B1, W2, B2 = update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "\n",
    "    if (i%20)==0:\n",
    "      print(\"Iteration number: \", i)\n",
    "      print(\"Accuracy = \", get_accuracy(get_predictions(A2), Y))\n",
    "  return W1, B1, W2, B2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  0\n",
      "Accuracy =  0.05601190476190476\n",
      "Iteration number:  20\n",
      "Accuracy =  0.38604166666666667\n",
      "Iteration number:  40\n",
      "Accuracy =  0.519375\n",
      "Iteration number:  60\n",
      "Accuracy =  0.5841964285714286\n",
      "Iteration number:  80\n",
      "Accuracy =  0.6279464285714286\n",
      "Iteration number:  100\n",
      "Accuracy =  0.6620833333333334\n",
      "Iteration number:  120\n",
      "Accuracy =  0.6881547619047619\n",
      "Iteration number:  140\n",
      "Accuracy =  0.7094642857142858\n",
      "Iteration number:  160\n",
      "Accuracy =  0.7267559523809524\n",
      "Iteration number:  180\n",
      "Accuracy =  0.7422619047619048\n",
      "Iteration number:  200\n",
      "Accuracy =  0.7552380952380953\n",
      "Iteration number:  220\n",
      "Accuracy =  0.7661607142857143\n",
      "Iteration number:  240\n",
      "Accuracy =  0.7752678571428572\n",
      "Iteration number:  260\n",
      "Accuracy =  0.7830059523809524\n",
      "Iteration number:  280\n",
      "Accuracy =  0.7901785714285714\n",
      "Iteration number:  300\n",
      "Accuracy =  0.7972023809523809\n",
      "Iteration number:  320\n",
      "Accuracy =  0.8030357142857143\n",
      "Iteration number:  340\n",
      "Accuracy =  0.8087797619047619\n",
      "Iteration number:  360\n",
      "Accuracy =  0.8137797619047619\n",
      "Iteration number:  380\n",
      "Accuracy =  0.8186607142857143\n",
      "Iteration number:  400\n",
      "Accuracy =  0.8227380952380953\n",
      "Iteration number:  420\n",
      "Accuracy =  0.8261607142857142\n",
      "Iteration number:  440\n",
      "Accuracy =  0.8297619047619048\n",
      "Iteration number:  460\n",
      "Accuracy =  0.832827380952381\n",
      "Iteration number:  480\n",
      "Accuracy =  0.8354464285714286\n",
      "Iteration number:  500\n",
      "Accuracy =  0.838452380952381\n",
      "Iteration number:  520\n",
      "Accuracy =  0.8410416666666667\n",
      "Iteration number:  540\n",
      "Accuracy =  0.8438095238095238\n",
      "Iteration number:  560\n",
      "Accuracy =  0.8456547619047619\n",
      "Iteration number:  580\n",
      "Accuracy =  0.8473511904761905\n",
      "Iteration number:  600\n",
      "Accuracy =  0.8496428571428571\n",
      "Iteration number:  620\n",
      "Accuracy =  0.8518154761904762\n",
      "Iteration number:  640\n",
      "Accuracy =  0.853452380952381\n",
      "Iteration number:  660\n",
      "Accuracy =  0.8552380952380952\n",
      "Iteration number:  680\n",
      "Accuracy =  0.8573809523809524\n",
      "Iteration number:  700\n",
      "Accuracy =  0.8588690476190476\n",
      "Iteration number:  720\n",
      "Accuracy =  0.8605654761904762\n",
      "Iteration number:  740\n",
      "Accuracy =  0.8623511904761905\n",
      "Iteration number:  760\n",
      "Accuracy =  0.8638690476190476\n",
      "Iteration number:  780\n",
      "Accuracy =  0.8651785714285715\n",
      "Iteration number:  800\n",
      "Accuracy =  0.8664583333333333\n",
      "Iteration number:  820\n",
      "Accuracy =  0.8675892857142857\n",
      "Iteration number:  840\n",
      "Accuracy =  0.8685416666666667\n",
      "Iteration number:  860\n",
      "Accuracy =  0.8698214285714285\n",
      "Iteration number:  880\n",
      "Accuracy =  0.8707738095238096\n",
      "Iteration number:  900\n",
      "Accuracy =  0.871904761904762\n",
      "Iteration number:  920\n",
      "Accuracy =  0.8727678571428571\n",
      "Iteration number:  940\n",
      "Accuracy =  0.8738988095238095\n",
      "Iteration number:  960\n",
      "Accuracy =  0.8750892857142857\n",
      "Iteration number:  980\n",
      "Accuracy =  0.8760416666666667\n",
      "Iteration number:  1000\n",
      "Accuracy =  0.8770833333333333\n",
      "Iteration number:  1020\n",
      "Accuracy =  0.8778571428571429\n",
      "Iteration number:  1040\n",
      "Accuracy =  0.8784821428571429\n",
      "Iteration number:  1060\n",
      "Accuracy =  0.8794940476190476\n",
      "Iteration number:  1080\n",
      "Accuracy =  0.8802380952380953\n",
      "Iteration number:  1100\n",
      "Accuracy =  0.8812202380952381\n",
      "Iteration number:  1120\n",
      "Accuracy =  0.8820535714285714\n",
      "Iteration number:  1140\n",
      "Accuracy =  0.8831845238095238\n",
      "Iteration number:  1160\n",
      "Accuracy =  0.884077380952381\n",
      "Iteration number:  1180\n",
      "Accuracy =  0.8850297619047619\n",
      "Iteration number:  1200\n",
      "Accuracy =  0.8857142857142857\n",
      "Iteration number:  1220\n",
      "Accuracy =  0.886547619047619\n",
      "Iteration number:  1240\n",
      "Accuracy =  0.887172619047619\n",
      "Iteration number:  1260\n",
      "Accuracy =  0.8880059523809524\n",
      "Iteration number:  1280\n",
      "Accuracy =  0.8884226190476191\n",
      "Iteration number:  1300\n",
      "Accuracy =  0.8891666666666667\n",
      "Iteration number:  1320\n",
      "Accuracy =  0.8898214285714285\n",
      "Iteration number:  1340\n",
      "Accuracy =  0.8902678571428572\n",
      "Iteration number:  1360\n",
      "Accuracy =  0.8907440476190476\n",
      "Iteration number:  1380\n",
      "Accuracy =  0.8911904761904762\n",
      "Iteration number:  1400\n",
      "Accuracy =  0.8918154761904762\n",
      "Iteration number:  1420\n",
      "Accuracy =  0.8923511904761905\n",
      "Iteration number:  1440\n",
      "Accuracy =  0.8928273809523809\n",
      "Iteration number:  1460\n",
      "Accuracy =  0.8932440476190476\n",
      "Iteration number:  1480\n",
      "Accuracy =  0.8937797619047619\n",
      "Iteration number:  1500\n",
      "Accuracy =  0.8944940476190476\n",
      "Iteration number:  1520\n",
      "Accuracy =  0.8952678571428572\n",
      "Iteration number:  1540\n",
      "Accuracy =  0.895625\n",
      "Iteration number:  1560\n",
      "Accuracy =  0.8959821428571428\n",
      "Iteration number:  1580\n",
      "Accuracy =  0.8964285714285715\n",
      "Iteration number:  1600\n",
      "Accuracy =  0.8969047619047619\n",
      "Iteration number:  1620\n",
      "Accuracy =  0.8975892857142858\n",
      "Iteration number:  1640\n",
      "Accuracy =  0.8980059523809524\n",
      "Iteration number:  1660\n",
      "Accuracy =  0.898422619047619\n",
      "Iteration number:  1680\n",
      "Accuracy =  0.8986607142857143\n",
      "Iteration number:  1700\n",
      "Accuracy =  0.8989880952380952\n",
      "Iteration number:  1720\n",
      "Accuracy =  0.8994047619047619\n",
      "Iteration number:  1740\n",
      "Accuracy =  0.8998511904761904\n",
      "Iteration number:  1760\n",
      "Accuracy =  0.9001785714285714\n",
      "Iteration number:  1780\n",
      "Accuracy =  0.9005357142857143\n",
      "Iteration number:  1800\n",
      "Accuracy =  0.9010119047619047\n",
      "Iteration number:  1820\n",
      "Accuracy =  0.9013988095238096\n",
      "Iteration number:  1840\n",
      "Accuracy =  0.9017559523809524\n",
      "Iteration number:  1860\n",
      "Accuracy =  0.9019642857142857\n",
      "Iteration number:  1880\n",
      "Accuracy =  0.9020833333333333\n",
      "Iteration number:  1900\n",
      "Accuracy =  0.9024702380952381\n",
      "Iteration number:  1920\n",
      "Accuracy =  0.9029761904761905\n",
      "Iteration number:  1940\n",
      "Accuracy =  0.9032440476190476\n",
      "Iteration number:  1960\n",
      "Accuracy =  0.9035416666666667\n",
      "Iteration number:  1980\n",
      "Accuracy =  0.9040178571428571\n",
      "Iteration number:  2000\n",
      "Accuracy =  0.9042559523809524\n",
      "Iteration number:  2020\n",
      "Accuracy =  0.904702380952381\n",
      "Iteration number:  2040\n",
      "Accuracy =  0.9049107142857142\n",
      "Iteration number:  2060\n",
      "Accuracy =  0.9050595238095238\n",
      "Iteration number:  2080\n",
      "Accuracy =  0.9050297619047619\n",
      "Iteration number:  2100\n",
      "Accuracy =  0.9052083333333333\n",
      "Iteration number:  2120\n",
      "Accuracy =  0.9055952380952381\n",
      "Iteration number:  2140\n",
      "Accuracy =  0.9058333333333334\n",
      "Iteration number:  2160\n",
      "Accuracy =  0.9060714285714285\n",
      "Iteration number:  2180\n",
      "Accuracy =  0.906547619047619\n",
      "Iteration number:  2200\n",
      "Accuracy =  0.9067559523809524\n",
      "Iteration number:  2220\n",
      "Accuracy =  0.9071130952380952\n",
      "Iteration number:  2240\n",
      "Accuracy =  0.9073511904761905\n",
      "Iteration number:  2260\n",
      "Accuracy =  0.9076488095238096\n",
      "Iteration number:  2280\n",
      "Accuracy =  0.9077678571428571\n",
      "Iteration number:  2300\n",
      "Accuracy =  0.9080654761904762\n",
      "Iteration number:  2320\n",
      "Accuracy =  0.9082440476190476\n",
      "Iteration number:  2340\n",
      "Accuracy =  0.908422619047619\n",
      "Iteration number:  2360\n",
      "Accuracy =  0.9086309523809524\n",
      "Iteration number:  2380\n",
      "Accuracy =  0.9090178571428571\n",
      "Iteration number:  2400\n",
      "Accuracy =  0.9092261904761905\n",
      "Iteration number:  2420\n",
      "Accuracy =  0.9095238095238095\n",
      "Iteration number:  2440\n",
      "Accuracy =  0.9098511904761905\n",
      "Iteration number:  2460\n",
      "Accuracy =  0.9100892857142857\n",
      "Iteration number:  2480\n",
      "Accuracy =  0.9102678571428572\n",
      "Iteration number:  2500\n",
      "Accuracy =  0.9104761904761904\n",
      "Iteration number:  2520\n",
      "Accuracy =  0.9108928571428572\n",
      "Iteration number:  2540\n",
      "Accuracy =  0.9113988095238095\n",
      "Iteration number:  2560\n",
      "Accuracy =  0.9116964285714285\n",
      "Iteration number:  2580\n",
      "Accuracy =  0.911875\n",
      "Iteration number:  2600\n",
      "Accuracy =  0.9120238095238096\n",
      "Iteration number:  2620\n",
      "Accuracy =  0.9122023809523809\n",
      "Iteration number:  2640\n",
      "Accuracy =  0.9124404761904762\n",
      "Iteration number:  2660\n",
      "Accuracy =  0.9127083333333333\n",
      "Iteration number:  2680\n",
      "Accuracy =  0.913125\n",
      "Iteration number:  2700\n",
      "Accuracy =  0.9132440476190476\n",
      "Iteration number:  2720\n",
      "Accuracy =  0.9135714285714286\n",
      "Iteration number:  2740\n",
      "Accuracy =  0.91375\n",
      "Iteration number:  2760\n",
      "Accuracy =  0.913779761904762\n",
      "Iteration number:  2780\n",
      "Accuracy =  0.913779761904762\n",
      "Iteration number:  2800\n",
      "Accuracy =  0.9139583333333333\n",
      "Iteration number:  2820\n",
      "Accuracy =  0.9142857142857143\n",
      "Iteration number:  2840\n",
      "Accuracy =  0.914375\n",
      "Iteration number:  2860\n",
      "Accuracy =  0.914702380952381\n",
      "Iteration number:  2880\n",
      "Accuracy =  0.9147619047619048\n",
      "Iteration number:  2900\n",
      "Accuracy =  0.9148809523809524\n",
      "Iteration number:  2920\n",
      "Accuracy =  0.9152380952380952\n",
      "Iteration number:  2940\n",
      "Accuracy =  0.9152976190476191\n",
      "Iteration number:  2960\n",
      "Accuracy =  0.9155654761904762\n",
      "Iteration number:  2980\n",
      "Accuracy =  0.9157738095238095\n",
      "Iteration number:  3000\n",
      "Accuracy =  0.9158630952380953\n",
      "Iteration number:  3020\n",
      "Accuracy =  0.9159821428571429\n",
      "Iteration number:  3040\n",
      "Accuracy =  0.9162202380952381\n",
      "Iteration number:  3060\n",
      "Accuracy =  0.9161904761904762\n",
      "Iteration number:  3080\n",
      "Accuracy =  0.9163988095238095\n",
      "Iteration number:  3100\n",
      "Accuracy =  0.9167261904761905\n",
      "Iteration number:  3120\n",
      "Accuracy =  0.9169047619047619\n",
      "Iteration number:  3140\n",
      "Accuracy =  0.9171428571428571\n",
      "Iteration number:  3160\n",
      "Accuracy =  0.9173809523809524\n",
      "Iteration number:  3180\n",
      "Accuracy =  0.9175\n",
      "Iteration number:  3200\n",
      "Accuracy =  0.9176488095238096\n",
      "Iteration number:  3220\n",
      "Accuracy =  0.9180059523809524\n",
      "Iteration number:  3240\n",
      "Accuracy =  0.9183630952380952\n",
      "Iteration number:  3260\n",
      "Accuracy =  0.9184821428571428\n",
      "Iteration number:  3280\n",
      "Accuracy =  0.9185416666666667\n",
      "Iteration number:  3300\n",
      "Accuracy =  0.91875\n",
      "Iteration number:  3320\n",
      "Accuracy =  0.9188988095238095\n",
      "Iteration number:  3340\n",
      "Accuracy =  0.919047619047619\n",
      "Iteration number:  3360\n",
      "Accuracy =  0.9192261904761905\n",
      "Iteration number:  3380\n",
      "Accuracy =  0.9195535714285714\n",
      "Iteration number:  3400\n",
      "Accuracy =  0.9196428571428571\n",
      "Iteration number:  3420\n",
      "Accuracy =  0.9199107142857142\n",
      "Iteration number:  3440\n",
      "Accuracy =  0.9200297619047619\n",
      "Iteration number:  3460\n",
      "Accuracy =  0.9202083333333333\n",
      "Iteration number:  3480\n",
      "Accuracy =  0.920327380952381\n",
      "Iteration number:  3500\n",
      "Accuracy =  0.9205952380952381\n",
      "Iteration number:  3520\n",
      "Accuracy =  0.9206845238095238\n",
      "Iteration number:  3540\n",
      "Accuracy =  0.9206845238095238\n",
      "Iteration number:  3560\n",
      "Accuracy =  0.9207440476190476\n",
      "Iteration number:  3580\n",
      "Accuracy =  0.9209226190476191\n",
      "Iteration number:  3600\n",
      "Accuracy =  0.9209821428571429\n",
      "Iteration number:  3620\n",
      "Accuracy =  0.9210416666666666\n",
      "Iteration number:  3640\n",
      "Accuracy =  0.9210416666666666\n",
      "Iteration number:  3660\n",
      "Accuracy =  0.9211607142857143\n",
      "Iteration number:  3680\n",
      "Accuracy =  0.9214285714285714\n",
      "Iteration number:  3700\n",
      "Accuracy =  0.9216369047619047\n",
      "Iteration number:  3720\n",
      "Accuracy =  0.9218154761904762\n",
      "Iteration number:  3740\n",
      "Accuracy =  0.921875\n",
      "Iteration number:  3760\n",
      "Accuracy =  0.9220535714285715\n",
      "Iteration number:  3780\n",
      "Accuracy =  0.9221428571428572\n",
      "Iteration number:  3800\n",
      "Accuracy =  0.9221428571428572\n",
      "Iteration number:  3820\n",
      "Accuracy =  0.9223511904761905\n",
      "Iteration number:  3840\n",
      "Accuracy =  0.9224107142857143\n",
      "Iteration number:  3860\n",
      "Accuracy =  0.9225297619047619\n",
      "Iteration number:  3880\n",
      "Accuracy =  0.9228273809523809\n",
      "Iteration number:  3900\n",
      "Accuracy =  0.9229761904761905\n",
      "Iteration number:  3920\n",
      "Accuracy =  0.9231547619047619\n",
      "Iteration number:  3940\n",
      "Accuracy =  0.9233035714285714\n",
      "Iteration number:  3960\n",
      "Accuracy =  0.9233928571428571\n",
      "Iteration number:  3980\n",
      "Accuracy =  0.9233928571428571\n",
      "Iteration number:  4000\n",
      "Accuracy =  0.923422619047619\n",
      "Iteration number:  4020\n",
      "Accuracy =  0.9235416666666667\n",
      "Iteration number:  4040\n",
      "Accuracy =  0.9236309523809524\n",
      "Iteration number:  4060\n",
      "Accuracy =  0.9238690476190476\n",
      "Iteration number:  4080\n",
      "Accuracy =  0.9239880952380952\n",
      "Iteration number:  4100\n",
      "Accuracy =  0.9239880952380952\n",
      "Iteration number:  4120\n",
      "Accuracy =  0.924047619047619\n",
      "Iteration number:  4140\n",
      "Accuracy =  0.9241666666666667\n",
      "Iteration number:  4160\n",
      "Accuracy =  0.9242559523809524\n",
      "Iteration number:  4180\n",
      "Accuracy =  0.9242857142857143\n",
      "Iteration number:  4200\n",
      "Accuracy =  0.924375\n",
      "Iteration number:  4220\n",
      "Accuracy =  0.9244940476190476\n",
      "Iteration number:  4240\n",
      "Accuracy =  0.924672619047619\n",
      "Iteration number:  4260\n",
      "Accuracy =  0.9247321428571429\n",
      "Iteration number:  4280\n",
      "Accuracy =  0.9248511904761905\n",
      "Iteration number:  4300\n",
      "Accuracy =  0.9250297619047619\n",
      "Iteration number:  4320\n",
      "Accuracy =  0.9252083333333333\n",
      "Iteration number:  4340\n",
      "Accuracy =  0.9254761904761905\n",
      "Iteration number:  4360\n",
      "Accuracy =  0.9256547619047619\n",
      "Iteration number:  4380\n",
      "Accuracy =  0.9257440476190476\n",
      "Iteration number:  4400\n",
      "Accuracy =  0.9258928571428572\n",
      "Iteration number:  4420\n",
      "Accuracy =  0.9259821428571429\n",
      "Iteration number:  4440\n",
      "Accuracy =  0.9260119047619048\n",
      "Iteration number:  4460\n",
      "Accuracy =  0.9262202380952381\n",
      "Iteration number:  4480\n",
      "Accuracy =  0.9263392857142857\n",
      "Iteration number:  4500\n",
      "Accuracy =  0.9263988095238095\n",
      "Iteration number:  4520\n",
      "Accuracy =  0.9265476190476191\n",
      "Iteration number:  4540\n",
      "Accuracy =  0.9266071428571429\n",
      "Iteration number:  4560\n",
      "Accuracy =  0.9267857142857143\n",
      "Iteration number:  4580\n",
      "Accuracy =  0.9268154761904762\n",
      "Iteration number:  4600\n",
      "Accuracy =  0.9269642857142857\n",
      "Iteration number:  4620\n",
      "Accuracy =  0.9271130952380953\n",
      "Iteration number:  4640\n",
      "Accuracy =  0.9272619047619047\n",
      "Iteration number:  4660\n",
      "Accuracy =  0.9274107142857143\n",
      "Iteration number:  4680\n",
      "Accuracy =  0.9273511904761905\n",
      "Iteration number:  4700\n",
      "Accuracy =  0.9273214285714285\n",
      "Iteration number:  4720\n",
      "Accuracy =  0.9273214285714285\n",
      "Iteration number:  4740\n",
      "Accuracy =  0.927202380952381\n",
      "Iteration number:  4760\n",
      "Accuracy =  0.9272916666666666\n",
      "Iteration number:  4780\n",
      "Accuracy =  0.9274702380952381\n",
      "Iteration number:  4800\n",
      "Accuracy =  0.9275595238095238\n",
      "Iteration number:  4820\n",
      "Accuracy =  0.9275595238095238\n",
      "Iteration number:  4840\n",
      "Accuracy =  0.927797619047619\n",
      "Iteration number:  4860\n",
      "Accuracy =  0.9278869047619047\n",
      "Iteration number:  4880\n",
      "Accuracy =  0.9279761904761905\n",
      "Iteration number:  4900\n",
      "Accuracy =  0.9280654761904762\n",
      "Iteration number:  4920\n",
      "Accuracy =  0.9280654761904762\n",
      "Iteration number:  4940\n",
      "Accuracy =  0.9281547619047619\n",
      "Iteration number:  4960\n",
      "Accuracy =  0.9282440476190477\n",
      "Iteration number:  4980\n",
      "Accuracy =  0.9282440476190477\n"
     ]
    }
   ],
   "source": [
    "W1,B1,W2,B2=gradient_descent(X_train,Y_train,0.10,5000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Actual:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data=4\n",
    "\n",
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val[:, val_data, None])\n",
    "\n",
    "print(\"Prediction: \", get_predictions(a2_val))\n",
    "print(\"Actual: \", Y_val[val_data])\n",
    "\n",
    "image_array= X_val[:, val_data].reshape(28, 28)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9145238095238095\n"
     ]
    }
   ],
   "source": [
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val)\n",
    "\n",
    "val_acc=get_accuracy(get_predictions(a2_val), Y_val)\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
