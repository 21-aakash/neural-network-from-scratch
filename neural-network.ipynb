{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "np.random.shuffle(data) #to avoid any prepattern , or porder just making ssure \n",
    "\n",
    "print(m,n)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of images = m = 42k\n",
    "\n",
    "we wanted the data in array form \n",
    "\n",
    "we  need to separate the label column and make n=764\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0:int(0.8*m), :]   #80% of the data is for training\n",
    "\n",
    "val_data = data[int(0.8*m):m, :]      #20% of the data is for validation\n",
    "\n",
    "X_train=train_data[:,1:].T       #taking all the rows and all the columns except the first one\n",
    "Y_train=train_data[:,0]           #taking all the rows and only the first column: puotput\n",
    "\n",
    "X_val=val_data[:,1:].T\n",
    "Y_val=val_data[:,0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 33600) (33600,) (784, 8400) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation of pixel values: \n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_val=X_val/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def  one_hot_converter(Y):\n",
    "    \n",
    "    one_hot_Y=np.zeros((Y.size, Y.max()+1))  #33600 x 10 matrix od zeroes \n",
    "    one_hot_Y[np.arange(Y.size),Y]=1            #putting one where y occures \n",
    "    one_hot_Y=one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "one_hot_converter(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  W1 = np.random.rand(10, 784) - 0.5\n",
    "  B1 = np.random.rand(10, 1) - 0.5\n",
    "  W2 = np.random.rand(10, 10) - 0.5\n",
    "  B2 = np.random.rand(10, 1) - 0.5\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def ReLU(X):\n",
    "  return np.maximum(X, 0)      #if x is greater than 0 then return x else return 0\n",
    "\n",
    "def softmax_calculator(Z):\n",
    "  return np.exp(Z) / sum(np.exp(Z))   \n",
    "\n",
    "def forward_propagation(W1, B1, W2, B2, X):\n",
    "  Z1 = W1.dot(X) + B1        #hidden layer 1          \n",
    "  A1 = ReLU(Z1)             #activation function\n",
    "  Z2 = W2.dot(A1) + B2      #hidden layer 2\n",
    "  A2 = softmax_calculator(Z2)   \n",
    "  return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_converter(Y):\n",
    "  one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "  one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "  return one_hot_Y.T\n",
    "\n",
    "def backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y):\n",
    "  one_hot_Y = one_hot_converter(Y)\n",
    "  dZ2 = A2 - one_hot_Y\n",
    "  dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "  dB2 = 1 / m * np.sum(dZ2)\n",
    "  dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "  dW1 = 1 / m * dZ1.dot(X.T)\n",
    "  dB1 = 1 / m * np.sum(dZ1)\n",
    "  return dW1, dB1, dW2, dB2\n",
    "\n",
    "def update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, learning_rate):\n",
    "  W1 = W1 - learning_rate * dW1\n",
    "  B1 = B1 - learning_rate * dB1\n",
    "  W2 = W2 - learning_rate * dW2\n",
    "  B2 = B2 - learning_rate * dB2\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "  W1, B1, W2, B2 = initialize_parameters()\n",
    "\n",
    "  for i in range(iterations):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(W1, B1, W2, B2, X)\n",
    "    dW1, dB1, dW2, dB2 = backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y)\n",
    "    W1, B1, W2, B2 = update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "\n",
    "    if (i%20)==0:\n",
    "      print(\"Iteration number: \", i)\n",
    "      print(\"Accuracy = \", get_accuracy(get_predictions(A2), Y))\n",
    "  return W1, B1, W2, B2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  0\n",
      "Accuracy =  0.05601190476190476\n",
      "Iteration number:  20\n",
      "Accuracy =  0.38604166666666667\n",
      "Iteration number:  40\n",
      "Accuracy =  0.519375\n",
      "Iteration number:  60\n",
      "Accuracy =  0.5841964285714286\n",
      "Iteration number:  80\n",
      "Accuracy =  0.6279464285714286\n",
      "Iteration number:  100\n",
      "Accuracy =  0.6620833333333334\n",
      "Iteration number:  120\n",
      "Accuracy =  0.6881547619047619\n",
      "Iteration number:  140\n",
      "Accuracy =  0.7094642857142858\n",
      "Iteration number:  160\n",
      "Accuracy =  0.7267559523809524\n",
      "Iteration number:  180\n",
      "Accuracy =  0.7422619047619048\n",
      "Iteration number:  200\n",
      "Accuracy =  0.7552380952380953\n",
      "Iteration number:  220\n",
      "Accuracy =  0.7661607142857143\n",
      "Iteration number:  240\n",
      "Accuracy =  0.7752678571428572\n",
      "Iteration number:  260\n",
      "Accuracy =  0.7830059523809524\n",
      "Iteration number:  280\n",
      "Accuracy =  0.7901785714285714\n",
      "Iteration number:  300\n",
      "Accuracy =  0.7972023809523809\n",
      "Iteration number:  320\n",
      "Accuracy =  0.8030357142857143\n",
      "Iteration number:  340\n",
      "Accuracy =  0.8087797619047619\n",
      "Iteration number:  360\n",
      "Accuracy =  0.8137797619047619\n",
      "Iteration number:  380\n",
      "Accuracy =  0.8186607142857143\n",
      "Iteration number:  400\n",
      "Accuracy =  0.8227380952380953\n",
      "Iteration number:  420\n",
      "Accuracy =  0.8261607142857142\n",
      "Iteration number:  440\n",
      "Accuracy =  0.8297619047619048\n",
      "Iteration number:  460\n",
      "Accuracy =  0.832827380952381\n",
      "Iteration number:  480\n",
      "Accuracy =  0.8354464285714286\n",
      "Iteration number:  500\n",
      "Accuracy =  0.838452380952381\n",
      "Iteration number:  520\n",
      "Accuracy =  0.8410416666666667\n",
      "Iteration number:  540\n",
      "Accuracy =  0.8438095238095238\n",
      "Iteration number:  560\n",
      "Accuracy =  0.8456547619047619\n",
      "Iteration number:  580\n",
      "Accuracy =  0.8473511904761905\n",
      "Iteration number:  600\n",
      "Accuracy =  0.8496428571428571\n",
      "Iteration number:  620\n",
      "Accuracy =  0.8518154761904762\n",
      "Iteration number:  640\n",
      "Accuracy =  0.853452380952381\n",
      "Iteration number:  660\n",
      "Accuracy =  0.8552380952380952\n",
      "Iteration number:  680\n",
      "Accuracy =  0.8573809523809524\n",
      "Iteration number:  700\n",
      "Accuracy =  0.8588690476190476\n",
      "Iteration number:  720\n",
      "Accuracy =  0.8605654761904762\n",
      "Iteration number:  740\n",
      "Accuracy =  0.8623511904761905\n",
      "Iteration number:  760\n",
      "Accuracy =  0.8638690476190476\n",
      "Iteration number:  780\n",
      "Accuracy =  0.8651785714285715\n",
      "Iteration number:  800\n",
      "Accuracy =  0.8664583333333333\n",
      "Iteration number:  820\n",
      "Accuracy =  0.8675892857142857\n",
      "Iteration number:  840\n",
      "Accuracy =  0.8685416666666667\n",
      "Iteration number:  860\n",
      "Accuracy =  0.8698214285714285\n",
      "Iteration number:  880\n",
      "Accuracy =  0.8707738095238096\n",
      "Iteration number:  900\n",
      "Accuracy =  0.871904761904762\n",
      "Iteration number:  920\n",
      "Accuracy =  0.8727678571428571\n",
      "Iteration number:  940\n",
      "Accuracy =  0.8738988095238095\n",
      "Iteration number:  960\n",
      "Accuracy =  0.8750892857142857\n",
      "Iteration number:  980\n",
      "Accuracy =  0.8760416666666667\n",
      "Iteration number:  1000\n",
      "Accuracy =  0.8770833333333333\n",
      "Iteration number:  1020\n",
      "Accuracy =  0.8778571428571429\n",
      "Iteration number:  1040\n",
      "Accuracy =  0.8784821428571429\n",
      "Iteration number:  1060\n",
      "Accuracy =  0.8794940476190476\n",
      "Iteration number:  1080\n",
      "Accuracy =  0.8802380952380953\n",
      "Iteration number:  1100\n",
      "Accuracy =  0.8812202380952381\n",
      "Iteration number:  1120\n",
      "Accuracy =  0.8820535714285714\n",
      "Iteration number:  1140\n",
      "Accuracy =  0.8831845238095238\n",
      "Iteration number:  1160\n",
      "Accuracy =  0.884077380952381\n",
      "Iteration number:  1180\n",
      "Accuracy =  0.8850297619047619\n",
      "Iteration number:  1200\n",
      "Accuracy =  0.8857142857142857\n",
      "Iteration number:  1220\n",
      "Accuracy =  0.886547619047619\n",
      "Iteration number:  1240\n",
      "Accuracy =  0.887172619047619\n",
      "Iteration number:  1260\n",
      "Accuracy =  0.8880059523809524\n",
      "Iteration number:  1280\n",
      "Accuracy =  0.8884226190476191\n",
      "Iteration number:  1300\n",
      "Accuracy =  0.8891666666666667\n",
      "Iteration number:  1320\n",
      "Accuracy =  0.8898214285714285\n",
      "Iteration number:  1340\n",
      "Accuracy =  0.8902678571428572\n",
      "Iteration number:  1360\n",
      "Accuracy =  0.8907440476190476\n",
      "Iteration number:  1380\n",
      "Accuracy =  0.8911904761904762\n",
      "Iteration number:  1400\n",
      "Accuracy =  0.8918154761904762\n",
      "Iteration number:  1420\n",
      "Accuracy =  0.8923511904761905\n",
      "Iteration number:  1440\n",
      "Accuracy =  0.8928273809523809\n",
      "Iteration number:  1460\n",
      "Accuracy =  0.8932440476190476\n",
      "Iteration number:  1480\n",
      "Accuracy =  0.8937797619047619\n",
      "Iteration number:  1500\n",
      "Accuracy =  0.8944940476190476\n",
      "Iteration number:  1520\n",
      "Accuracy =  0.8952678571428572\n",
      "Iteration number:  1540\n",
      "Accuracy =  0.895625\n",
      "Iteration number:  1560\n",
      "Accuracy =  0.8959821428571428\n",
      "Iteration number:  1580\n",
      "Accuracy =  0.8964285714285715\n",
      "Iteration number:  1600\n",
      "Accuracy =  0.8969047619047619\n",
      "Iteration number:  1620\n",
      "Accuracy =  0.8975892857142858\n",
      "Iteration number:  1640\n",
      "Accuracy =  0.8980059523809524\n",
      "Iteration number:  1660\n",
      "Accuracy =  0.898422619047619\n",
      "Iteration number:  1680\n",
      "Accuracy =  0.8986607142857143\n",
      "Iteration number:  1700\n",
      "Accuracy =  0.8989880952380952\n",
      "Iteration number:  1720\n",
      "Accuracy =  0.8994047619047619\n",
      "Iteration number:  1740\n",
      "Accuracy =  0.8998511904761904\n",
      "Iteration number:  1760\n",
      "Accuracy =  0.9001785714285714\n",
      "Iteration number:  1780\n",
      "Accuracy =  0.9005357142857143\n",
      "Iteration number:  1800\n",
      "Accuracy =  0.9010119047619047\n",
      "Iteration number:  1820\n",
      "Accuracy =  0.9013988095238096\n",
      "Iteration number:  1840\n",
      "Accuracy =  0.9017559523809524\n",
      "Iteration number:  1860\n",
      "Accuracy =  0.9019642857142857\n",
      "Iteration number:  1880\n",
      "Accuracy =  0.9020833333333333\n",
      "Iteration number:  1900\n",
      "Accuracy =  0.9024702380952381\n",
      "Iteration number:  1920\n",
      "Accuracy =  0.9029761904761905\n",
      "Iteration number:  1940\n",
      "Accuracy =  0.9032440476190476\n",
      "Iteration number:  1960\n",
      "Accuracy =  0.9035416666666667\n",
      "Iteration number:  1980\n",
      "Accuracy =  0.9040178571428571\n",
      "Iteration number:  2000\n",
      "Accuracy =  0.9042559523809524\n",
      "Iteration number:  2020\n",
      "Accuracy =  0.904702380952381\n",
      "Iteration number:  2040\n",
      "Accuracy =  0.9049107142857142\n",
      "Iteration number:  2060\n",
      "Accuracy =  0.9050595238095238\n",
      "Iteration number:  2080\n",
      "Accuracy =  0.9050297619047619\n",
      "Iteration number:  2100\n",
      "Accuracy =  0.9052083333333333\n",
      "Iteration number:  2120\n",
      "Accuracy =  0.9055952380952381\n",
      "Iteration number:  2140\n",
      "Accuracy =  0.9058333333333334\n",
      "Iteration number:  2160\n",
      "Accuracy =  0.9060714285714285\n",
      "Iteration number:  2180\n",
      "Accuracy =  0.906547619047619\n",
      "Iteration number:  2200\n",
      "Accuracy =  0.9067559523809524\n",
      "Iteration number:  2220\n",
      "Accuracy =  0.9071130952380952\n",
      "Iteration number:  2240\n",
      "Accuracy =  0.9073511904761905\n",
      "Iteration number:  2260\n",
      "Accuracy =  0.9076488095238096\n",
      "Iteration number:  2280\n",
      "Accuracy =  0.9077678571428571\n",
      "Iteration number:  2300\n",
      "Accuracy =  0.9080654761904762\n",
      "Iteration number:  2320\n",
      "Accuracy =  0.9082440476190476\n",
      "Iteration number:  2340\n",
      "Accuracy =  0.908422619047619\n",
      "Iteration number:  2360\n",
      "Accuracy =  0.9086309523809524\n",
      "Iteration number:  2380\n",
      "Accuracy =  0.9090178571428571\n",
      "Iteration number:  2400\n",
      "Accuracy =  0.9092261904761905\n",
      "Iteration number:  2420\n",
      "Accuracy =  0.9095238095238095\n",
      "Iteration number:  2440\n",
      "Accuracy =  0.9098511904761905\n",
      "Iteration number:  2460\n",
      "Accuracy =  0.9100892857142857\n",
      "Iteration number:  2480\n",
      "Accuracy =  0.9102678571428572\n",
      "Iteration number:  2500\n",
      "Accuracy =  0.9104761904761904\n",
      "Iteration number:  2520\n",
      "Accuracy =  0.9108928571428572\n",
      "Iteration number:  2540\n",
      "Accuracy =  0.9113988095238095\n",
      "Iteration number:  2560\n",
      "Accuracy =  0.9116964285714285\n",
      "Iteration number:  2580\n",
      "Accuracy =  0.911875\n",
      "Iteration number:  2600\n",
      "Accuracy =  0.9120238095238096\n",
      "Iteration number:  2620\n",
      "Accuracy =  0.9122023809523809\n",
      "Iteration number:  2640\n",
      "Accuracy =  0.9124404761904762\n",
      "Iteration number:  2660\n",
      "Accuracy =  0.9127083333333333\n",
      "Iteration number:  2680\n",
      "Accuracy =  0.913125\n",
      "Iteration number:  2700\n",
      "Accuracy =  0.9132440476190476\n",
      "Iteration number:  2720\n",
      "Accuracy =  0.9135714285714286\n",
      "Iteration number:  2740\n",
      "Accuracy =  0.91375\n",
      "Iteration number:  2760\n",
      "Accuracy =  0.913779761904762\n",
      "Iteration number:  2780\n",
      "Accuracy =  0.913779761904762\n",
      "Iteration number:  2800\n",
      "Accuracy =  0.9139583333333333\n",
      "Iteration number:  2820\n",
      "Accuracy =  0.9142857142857143\n",
      "Iteration number:  2840\n",
      "Accuracy =  0.914375\n",
      "Iteration number:  2860\n",
      "Accuracy =  0.914702380952381\n",
      "Iteration number:  2880\n",
      "Accuracy =  0.9147619047619048\n",
      "Iteration number:  2900\n",
      "Accuracy =  0.9148809523809524\n",
      "Iteration number:  2920\n",
      "Accuracy =  0.9152380952380952\n",
      "Iteration number:  2940\n",
      "Accuracy =  0.9152976190476191\n",
      "Iteration number:  2960\n",
      "Accuracy =  0.9155654761904762\n",
      "Iteration number:  2980\n",
      "Accuracy =  0.9157738095238095\n",
      "Iteration number:  3000\n",
      "Accuracy =  0.9158630952380953\n",
      "Iteration number:  3020\n",
      "Accuracy =  0.9159821428571429\n",
      "Iteration number:  3040\n",
      "Accuracy =  0.9162202380952381\n",
      "Iteration number:  3060\n",
      "Accuracy =  0.9161904761904762\n",
      "Iteration number:  3080\n",
      "Accuracy =  0.9163988095238095\n",
      "Iteration number:  3100\n",
      "Accuracy =  0.9167261904761905\n",
      "Iteration number:  3120\n",
      "Accuracy =  0.9169047619047619\n",
      "Iteration number:  3140\n",
      "Accuracy =  0.9171428571428571\n",
      "Iteration number:  3160\n",
      "Accuracy =  0.9173809523809524\n",
      "Iteration number:  3180\n",
      "Accuracy =  0.9175\n",
      "Iteration number:  3200\n",
      "Accuracy =  0.9176488095238096\n",
      "Iteration number:  3220\n",
      "Accuracy =  0.9180059523809524\n",
      "Iteration number:  3240\n",
      "Accuracy =  0.9183630952380952\n",
      "Iteration number:  3260\n",
      "Accuracy =  0.9184821428571428\n",
      "Iteration number:  3280\n",
      "Accuracy =  0.9185416666666667\n",
      "Iteration number:  3300\n",
      "Accuracy =  0.91875\n",
      "Iteration number:  3320\n",
      "Accuracy =  0.9188988095238095\n",
      "Iteration number:  3340\n",
      "Accuracy =  0.919047619047619\n",
      "Iteration number:  3360\n",
      "Accuracy =  0.9192261904761905\n",
      "Iteration number:  3380\n",
      "Accuracy =  0.9195535714285714\n",
      "Iteration number:  3400\n",
      "Accuracy =  0.9196428571428571\n",
      "Iteration number:  3420\n",
      "Accuracy =  0.9199107142857142\n",
      "Iteration number:  3440\n",
      "Accuracy =  0.9200297619047619\n",
      "Iteration number:  3460\n",
      "Accuracy =  0.9202083333333333\n",
      "Iteration number:  3480\n",
      "Accuracy =  0.920327380952381\n",
      "Iteration number:  3500\n",
      "Accuracy =  0.9205952380952381\n",
      "Iteration number:  3520\n",
      "Accuracy =  0.9206845238095238\n",
      "Iteration number:  3540\n",
      "Accuracy =  0.9206845238095238\n",
      "Iteration number:  3560\n",
      "Accuracy =  0.9207440476190476\n",
      "Iteration number:  3580\n",
      "Accuracy =  0.9209226190476191\n",
      "Iteration number:  3600\n",
      "Accuracy =  0.9209821428571429\n",
      "Iteration number:  3620\n",
      "Accuracy =  0.9210416666666666\n",
      "Iteration number:  3640\n",
      "Accuracy =  0.9210416666666666\n",
      "Iteration number:  3660\n",
      "Accuracy =  0.9211607142857143\n",
      "Iteration number:  3680\n",
      "Accuracy =  0.9214285714285714\n",
      "Iteration number:  3700\n",
      "Accuracy =  0.9216369047619047\n",
      "Iteration number:  3720\n",
      "Accuracy =  0.9218154761904762\n",
      "Iteration number:  3740\n",
      "Accuracy =  0.921875\n",
      "Iteration number:  3760\n",
      "Accuracy =  0.9220535714285715\n",
      "Iteration number:  3780\n",
      "Accuracy =  0.9221428571428572\n",
      "Iteration number:  3800\n",
      "Accuracy =  0.9221428571428572\n",
      "Iteration number:  3820\n",
      "Accuracy =  0.9223511904761905\n",
      "Iteration number:  3840\n",
      "Accuracy =  0.9224107142857143\n",
      "Iteration number:  3860\n",
      "Accuracy =  0.9225297619047619\n",
      "Iteration number:  3880\n",
      "Accuracy =  0.9228273809523809\n",
      "Iteration number:  3900\n",
      "Accuracy =  0.9229761904761905\n",
      "Iteration number:  3920\n",
      "Accuracy =  0.9231547619047619\n",
      "Iteration number:  3940\n",
      "Accuracy =  0.9233035714285714\n",
      "Iteration number:  3960\n",
      "Accuracy =  0.9233928571428571\n",
      "Iteration number:  3980\n",
      "Accuracy =  0.9233928571428571\n",
      "Iteration number:  4000\n",
      "Accuracy =  0.923422619047619\n",
      "Iteration number:  4020\n",
      "Accuracy =  0.9235416666666667\n",
      "Iteration number:  4040\n",
      "Accuracy =  0.9236309523809524\n",
      "Iteration number:  4060\n",
      "Accuracy =  0.9238690476190476\n",
      "Iteration number:  4080\n",
      "Accuracy =  0.9239880952380952\n",
      "Iteration number:  4100\n",
      "Accuracy =  0.9239880952380952\n",
      "Iteration number:  4120\n",
      "Accuracy =  0.924047619047619\n",
      "Iteration number:  4140\n",
      "Accuracy =  0.9241666666666667\n",
      "Iteration number:  4160\n",
      "Accuracy =  0.9242559523809524\n",
      "Iteration number:  4180\n",
      "Accuracy =  0.9242857142857143\n",
      "Iteration number:  4200\n",
      "Accuracy =  0.924375\n",
      "Iteration number:  4220\n",
      "Accuracy =  0.9244940476190476\n",
      "Iteration number:  4240\n",
      "Accuracy =  0.924672619047619\n",
      "Iteration number:  4260\n",
      "Accuracy =  0.9247321428571429\n",
      "Iteration number:  4280\n",
      "Accuracy =  0.9248511904761905\n",
      "Iteration number:  4300\n",
      "Accuracy =  0.9250297619047619\n",
      "Iteration number:  4320\n",
      "Accuracy =  0.9252083333333333\n",
      "Iteration number:  4340\n",
      "Accuracy =  0.9254761904761905\n",
      "Iteration number:  4360\n",
      "Accuracy =  0.9256547619047619\n",
      "Iteration number:  4380\n",
      "Accuracy =  0.9257440476190476\n",
      "Iteration number:  4400\n",
      "Accuracy =  0.9258928571428572\n",
      "Iteration number:  4420\n",
      "Accuracy =  0.9259821428571429\n",
      "Iteration number:  4440\n",
      "Accuracy =  0.9260119047619048\n",
      "Iteration number:  4460\n",
      "Accuracy =  0.9262202380952381\n",
      "Iteration number:  4480\n",
      "Accuracy =  0.9263392857142857\n",
      "Iteration number:  4500\n",
      "Accuracy =  0.9263988095238095\n",
      "Iteration number:  4520\n",
      "Accuracy =  0.9265476190476191\n",
      "Iteration number:  4540\n",
      "Accuracy =  0.9266071428571429\n",
      "Iteration number:  4560\n",
      "Accuracy =  0.9267857142857143\n",
      "Iteration number:  4580\n",
      "Accuracy =  0.9268154761904762\n",
      "Iteration number:  4600\n",
      "Accuracy =  0.9269642857142857\n",
      "Iteration number:  4620\n",
      "Accuracy =  0.9271130952380953\n",
      "Iteration number:  4640\n",
      "Accuracy =  0.9272619047619047\n",
      "Iteration number:  4660\n",
      "Accuracy =  0.9274107142857143\n",
      "Iteration number:  4680\n",
      "Accuracy =  0.9273511904761905\n",
      "Iteration number:  4700\n",
      "Accuracy =  0.9273214285714285\n",
      "Iteration number:  4720\n",
      "Accuracy =  0.9273214285714285\n",
      "Iteration number:  4740\n",
      "Accuracy =  0.927202380952381\n",
      "Iteration number:  4760\n",
      "Accuracy =  0.9272916666666666\n",
      "Iteration number:  4780\n",
      "Accuracy =  0.9274702380952381\n",
      "Iteration number:  4800\n",
      "Accuracy =  0.9275595238095238\n",
      "Iteration number:  4820\n",
      "Accuracy =  0.9275595238095238\n",
      "Iteration number:  4840\n",
      "Accuracy =  0.927797619047619\n",
      "Iteration number:  4860\n",
      "Accuracy =  0.9278869047619047\n",
      "Iteration number:  4880\n",
      "Accuracy =  0.9279761904761905\n",
      "Iteration number:  4900\n",
      "Accuracy =  0.9280654761904762\n",
      "Iteration number:  4920\n",
      "Accuracy =  0.9280654761904762\n",
      "Iteration number:  4940\n",
      "Accuracy =  0.9281547619047619\n",
      "Iteration number:  4960\n",
      "Accuracy =  0.9282440476190477\n",
      "Iteration number:  4980\n",
      "Accuracy =  0.9282440476190477\n"
     ]
    }
   ],
   "source": [
    "W1,B1,W2,B2=gradient_descent(X_train,Y_train,0.10,5000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Actual:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data=0\n",
    "\n",
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val[:, val_data, None])\n",
    "\n",
    "print(\"Prediction: \", get_predictions(a2_val))\n",
    "print(\"Actual: \", Y_val[val_data])\n",
    "\n",
    "image_array= X_val[:, val_data].reshape(28, 28)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9145238095238095\n"
     ]
    }
   ],
   "source": [
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val)\n",
    "\n",
    "val_acc=get_accuracy(get_predictions(a2_val), Y_val)\n",
    "print(\"Validation accuracy: \", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
