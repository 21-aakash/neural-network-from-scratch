{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "np.random.shuffle(data) #to avoid any prepattern , or porder just making ssure \n",
    "\n",
    "print(m,n)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of images = m = 42k\n",
    "\n",
    "we wanted the data in array form \n",
    "\n",
    "we  need to separate the label column and make n=764\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0:int(0.8*m), :]   #80% of the data is for training\n",
    "\n",
    "val_data = data[int(0.8*m):m, :]      #20% of the data is for validation\n",
    "\n",
    "X_train=train_data[:,1:].T       #taking all the rows and all the columns except the first one\n",
    "Y_train=train_data[:,0]           #taking all the rows and only the first column: puotput\n",
    "\n",
    "X_val=val_data[:,1:].T\n",
    "Y_val=val_data[:,0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 33600) (33600,) (784, 8400) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation of pixel values: \n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_val=X_val/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def  one_hot_converter(Y):\n",
    "    \n",
    "    one_hot_Y=np.zeros((Y.size, Y.max()+1))  #33600 x 10 matrix od zeroes \n",
    "    one_hot_Y[np.arange(Y.size),Y]=1            #putting one where y occures \n",
    "    one_hot_Y=one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "one_hot_converter(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  W1 = np.random.rand(10, 784) - 0.5\n",
    "  B1 = np.random.rand(10, 1) - 0.5\n",
    "  W2 = np.random.rand(10, 10) - 0.5\n",
    "  B2 = np.random.rand(10, 1) - 0.5\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def ReLU(X):\n",
    "  return np.maximum(X, 0)      #if x is greater than 0 then return x else return 0\n",
    "\n",
    "def softmax_calculator(Z):\n",
    "  return np.exp(Z) / sum(np.exp(Z))   \n",
    "\n",
    "def forward_propagation(W1, B1, W2, B2, X):\n",
    "  Z1 = W1.dot(X) + B1        #hidden layer 1          \n",
    "  A1 = ReLU(Z1)             #activation function\n",
    "  Z2 = W2.dot(A1) + B2      #hidden layer 2\n",
    "  A2 = softmax_calculator(Z2)   \n",
    "  return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_converter(Y):\n",
    "  one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "  one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "  return one_hot_Y.T\n",
    "\n",
    "def backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y):\n",
    "  one_hot_Y = one_hot_converter(Y)\n",
    "  dZ2 = A2 - one_hot_Y\n",
    "  dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "  dB2 = 1 / m * np.sum(dZ2)\n",
    "  dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "  dW1 = 1 / m * dZ1.dot(X.T)\n",
    "  dB1 = 1 / m * np.sum(dZ1)\n",
    "  return dW1, dB1, dW2, dB2\n",
    "\n",
    "def update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, learning_rate):\n",
    "  W1 = W1 - learning_rate * dW1\n",
    "  B1 = B1 - learning_rate * dB1\n",
    "  W2 = W2 - learning_rate * dW2\n",
    "  B2 = B2 - learning_rate * dB2\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "  W1, B1, W2, B2 = initialize_parameters()\n",
    "\n",
    "  for i in range(iterations):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(W1, B1, W2, B2, X)\n",
    "    dW1, dB1, dW2, dB2 = backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y)\n",
    "    W1, B1, W2, B2 = update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "\n",
    "    if (i%20)==0:\n",
    "      print(\"Iteration number: \", i)\n",
    "      print(\"Accuracy = \", get_accuracy(get_predictions(A2), Y))\n",
    "  return W1, B1, W2, B2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  0\n",
      "Accuracy =  0.10794642857142857\n",
      "Iteration number:  20\n",
      "Accuracy =  0.23791666666666667\n",
      "Iteration number:  40\n",
      "Accuracy =  0.2817857142857143\n",
      "Iteration number:  60\n",
      "Accuracy =  0.3437202380952381\n",
      "Iteration number:  80\n",
      "Accuracy =  0.43166666666666664\n",
      "Iteration number:  100\n",
      "Accuracy =  0.5001785714285715\n",
      "Iteration number:  120\n",
      "Accuracy =  0.5591369047619048\n",
      "Iteration number:  140\n",
      "Accuracy =  0.6081845238095238\n",
      "Iteration number:  160\n",
      "Accuracy =  0.6475595238095239\n",
      "Iteration number:  180\n",
      "Accuracy =  0.6772321428571428\n",
      "Iteration number:  200\n",
      "Accuracy =  0.7026785714285714\n",
      "Iteration number:  220\n",
      "Accuracy =  0.7214583333333333\n",
      "Iteration number:  240\n",
      "Accuracy =  0.737827380952381\n",
      "Iteration number:  260\n",
      "Accuracy =  0.752529761904762\n",
      "Iteration number:  280\n",
      "Accuracy =  0.7652976190476191\n",
      "Iteration number:  300\n",
      "Accuracy =  0.7766666666666666\n",
      "Iteration number:  320\n",
      "Accuracy =  0.7853869047619048\n",
      "Iteration number:  340\n",
      "Accuracy =  0.7935416666666667\n",
      "Iteration number:  360\n",
      "Accuracy =  0.8005357142857142\n",
      "Iteration number:  380\n",
      "Accuracy =  0.8064583333333334\n",
      "Iteration number:  400\n",
      "Accuracy =  0.8116071428571429\n",
      "Iteration number:  420\n",
      "Accuracy =  0.8167559523809523\n",
      "Iteration number:  440\n",
      "Accuracy =  0.8212797619047619\n",
      "Iteration number:  460\n",
      "Accuracy =  0.825595238095238\n",
      "Iteration number:  480\n",
      "Accuracy =  0.8292261904761905\n",
      "Iteration number:  500\n",
      "Accuracy =  0.8320833333333333\n",
      "Iteration number:  520\n",
      "Accuracy =  0.8347321428571428\n",
      "Iteration number:  540\n",
      "Accuracy =  0.8373214285714285\n",
      "Iteration number:  560\n",
      "Accuracy =  0.8401785714285714\n",
      "Iteration number:  580\n",
      "Accuracy =  0.8425\n",
      "Iteration number:  600\n",
      "Accuracy =  0.8446130952380952\n",
      "Iteration number:  620\n",
      "Accuracy =  0.846577380952381\n",
      "Iteration number:  640\n",
      "Accuracy =  0.8487202380952381\n",
      "Iteration number:  660\n",
      "Accuracy =  0.8507142857142858\n",
      "Iteration number:  680\n",
      "Accuracy =  0.8525595238095238\n",
      "Iteration number:  700\n",
      "Accuracy =  0.8543154761904762\n",
      "Iteration number:  720\n",
      "Accuracy =  0.8560714285714286\n",
      "Iteration number:  740\n",
      "Accuracy =  0.8573809523809524\n",
      "Iteration number:  760\n",
      "Accuracy =  0.859077380952381\n",
      "Iteration number:  780\n",
      "Accuracy =  0.8604761904761905\n",
      "Iteration number:  800\n",
      "Accuracy =  0.8620238095238095\n",
      "Iteration number:  820\n",
      "Accuracy =  0.8636011904761904\n",
      "Iteration number:  840\n",
      "Accuracy =  0.8651190476190476\n",
      "Iteration number:  860\n",
      "Accuracy =  0.8662797619047619\n",
      "Iteration number:  880\n",
      "Accuracy =  0.8673511904761905\n",
      "Iteration number:  900\n",
      "Accuracy =  0.8680952380952381\n",
      "Iteration number:  920\n",
      "Accuracy =  0.8691071428571429\n",
      "Iteration number:  940\n",
      "Accuracy =  0.87\n",
      "Iteration number:  960\n",
      "Accuracy =  0.8707738095238096\n",
      "Iteration number:  980\n",
      "Accuracy =  0.8714880952380952\n",
      "Iteration number:  1000\n",
      "Accuracy =  0.8723214285714286\n",
      "Iteration number:  1020\n",
      "Accuracy =  0.8730952380952381\n",
      "Iteration number:  1040\n",
      "Accuracy =  0.8735416666666667\n",
      "Iteration number:  1060\n",
      "Accuracy =  0.8741369047619048\n",
      "Iteration number:  1080\n",
      "Accuracy =  0.8747619047619047\n",
      "Iteration number:  1100\n",
      "Accuracy =  0.8754761904761905\n",
      "Iteration number:  1120\n",
      "Accuracy =  0.8762797619047619\n",
      "Iteration number:  1140\n",
      "Accuracy =  0.8768154761904762\n",
      "Iteration number:  1160\n",
      "Accuracy =  0.8774107142857143\n",
      "Iteration number:  1180\n",
      "Accuracy =  0.8779761904761905\n",
      "Iteration number:  1200\n",
      "Accuracy =  0.8783630952380952\n",
      "Iteration number:  1220\n",
      "Accuracy =  0.8788095238095238\n",
      "Iteration number:  1240\n",
      "Accuracy =  0.879375\n",
      "Iteration number:  1260\n",
      "Accuracy =  0.8798214285714285\n",
      "Iteration number:  1280\n",
      "Accuracy =  0.8802380952380953\n",
      "Iteration number:  1300\n",
      "Accuracy =  0.880625\n",
      "Iteration number:  1320\n",
      "Accuracy =  0.8813095238095238\n",
      "Iteration number:  1340\n",
      "Accuracy =  0.8819345238095239\n",
      "Iteration number:  1360\n",
      "Accuracy =  0.8823809523809524\n",
      "Iteration number:  1380\n",
      "Accuracy =  0.8827678571428571\n",
      "Iteration number:  1400\n",
      "Accuracy =  0.8831547619047619\n",
      "Iteration number:  1420\n",
      "Accuracy =  0.8834821428571429\n",
      "Iteration number:  1440\n",
      "Accuracy =  0.8840178571428572\n",
      "Iteration number:  1460\n",
      "Accuracy =  0.8842261904761904\n",
      "Iteration number:  1480\n",
      "Accuracy =  0.8847619047619047\n",
      "Iteration number:  1500\n",
      "Accuracy =  0.8851488095238095\n",
      "Iteration number:  1520\n",
      "Accuracy =  0.8856547619047619\n",
      "Iteration number:  1540\n",
      "Accuracy =  0.8858630952380953\n",
      "Iteration number:  1560\n",
      "Accuracy =  0.8861607142857143\n",
      "Iteration number:  1580\n",
      "Accuracy =  0.8864285714285715\n",
      "Iteration number:  1600\n",
      "Accuracy =  0.8869047619047619\n",
      "Iteration number:  1620\n",
      "Accuracy =  0.8872321428571428\n",
      "Iteration number:  1640\n",
      "Accuracy =  0.887797619047619\n",
      "Iteration number:  1660\n",
      "Accuracy =  0.8883630952380952\n",
      "Iteration number:  1680\n",
      "Accuracy =  0.8886904761904761\n",
      "Iteration number:  1700\n",
      "Accuracy =  0.8891071428571429\n",
      "Iteration number:  1720\n",
      "Accuracy =  0.8893154761904762\n",
      "Iteration number:  1740\n",
      "Accuracy =  0.8895833333333333\n",
      "Iteration number:  1760\n",
      "Accuracy =  0.8900297619047619\n",
      "Iteration number:  1780\n",
      "Accuracy =  0.8904166666666666\n",
      "Iteration number:  1800\n",
      "Accuracy =  0.8908035714285715\n",
      "Iteration number:  1820\n",
      "Accuracy =  0.8909821428571428\n",
      "Iteration number:  1840\n",
      "Accuracy =  0.891547619047619\n",
      "Iteration number:  1860\n",
      "Accuracy =  0.8916964285714286\n",
      "Iteration number:  1880\n",
      "Accuracy =  0.892172619047619\n",
      "Iteration number:  1900\n",
      "Accuracy =  0.8925\n",
      "Iteration number:  1920\n",
      "Accuracy =  0.8928869047619048\n",
      "Iteration number:  1940\n",
      "Accuracy =  0.8932440476190476\n",
      "Iteration number:  1960\n",
      "Accuracy =  0.8938095238095238\n",
      "Iteration number:  1980\n",
      "Accuracy =  0.894077380952381\n",
      "Iteration number:  2000\n",
      "Accuracy =  0.8942559523809523\n",
      "Iteration number:  2020\n",
      "Accuracy =  0.894375\n",
      "Iteration number:  2040\n",
      "Accuracy =  0.8947916666666667\n",
      "Iteration number:  2060\n",
      "Accuracy =  0.895\n",
      "Iteration number:  2080\n",
      "Accuracy =  0.8952678571428572\n",
      "Iteration number:  2100\n",
      "Accuracy =  0.895327380952381\n",
      "Iteration number:  2120\n",
      "Accuracy =  0.8955952380952381\n",
      "Iteration number:  2140\n",
      "Accuracy =  0.8958928571428572\n",
      "Iteration number:  2160\n",
      "Accuracy =  0.8960416666666666\n",
      "Iteration number:  2180\n",
      "Accuracy =  0.8965178571428571\n",
      "Iteration number:  2200\n",
      "Accuracy =  0.8967857142857143\n",
      "Iteration number:  2220\n",
      "Accuracy =  0.8970238095238096\n",
      "Iteration number:  2240\n",
      "Accuracy =  0.8972321428571428\n",
      "Iteration number:  2260\n",
      "Accuracy =  0.8975892857142858\n",
      "Iteration number:  2280\n",
      "Accuracy =  0.8977678571428571\n",
      "Iteration number:  2300\n",
      "Accuracy =  0.8980357142857143\n",
      "Iteration number:  2320\n",
      "Accuracy =  0.898154761904762\n",
      "Iteration number:  2340\n",
      "Accuracy =  0.8983928571428571\n",
      "Iteration number:  2360\n",
      "Accuracy =  0.8987797619047619\n",
      "Iteration number:  2380\n",
      "Accuracy =  0.8988095238095238\n",
      "Iteration number:  2400\n",
      "Accuracy =  0.899077380952381\n",
      "Iteration number:  2420\n",
      "Accuracy =  0.8992261904761905\n",
      "Iteration number:  2440\n",
      "Accuracy =  0.8993452380952381\n",
      "Iteration number:  2460\n",
      "Accuracy =  0.8994940476190476\n",
      "Iteration number:  2480\n",
      "Accuracy =  0.8996726190476191\n",
      "Iteration number:  2500\n",
      "Accuracy =  0.899702380952381\n",
      "Iteration number:  2520\n",
      "Accuracy =  0.8997916666666667\n",
      "Iteration number:  2540\n",
      "Accuracy =  0.9001785714285714\n",
      "Iteration number:  2560\n",
      "Accuracy =  0.9002380952380953\n",
      "Iteration number:  2580\n",
      "Accuracy =  0.9004761904761904\n",
      "Iteration number:  2600\n",
      "Accuracy =  0.9005952380952381\n",
      "Iteration number:  2620\n",
      "Accuracy =  0.9006547619047619\n",
      "Iteration number:  2640\n",
      "Accuracy =  0.9006845238095238\n",
      "Iteration number:  2660\n",
      "Accuracy =  0.900952380952381\n",
      "Iteration number:  2680\n",
      "Accuracy =  0.9010714285714285\n",
      "Iteration number:  2700\n",
      "Accuracy =  0.9011904761904762\n",
      "Iteration number:  2720\n",
      "Accuracy =  0.9013392857142857\n",
      "Iteration number:  2740\n",
      "Accuracy =  0.9013095238095238\n",
      "Iteration number:  2760\n",
      "Accuracy =  0.9013690476190476\n",
      "Iteration number:  2780\n",
      "Accuracy =  0.9013392857142857\n",
      "Iteration number:  2800\n",
      "Accuracy =  0.9015773809523809\n",
      "Iteration number:  2820\n",
      "Accuracy =  0.9017559523809524\n",
      "Iteration number:  2840\n",
      "Accuracy =  0.901875\n",
      "Iteration number:  2860\n",
      "Accuracy =  0.9019642857142857\n",
      "Iteration number:  2880\n",
      "Accuracy =  0.902172619047619\n",
      "Iteration number:  2900\n",
      "Accuracy =  0.9023214285714286\n",
      "Iteration number:  2920\n",
      "Accuracy =  0.9024107142857143\n",
      "Iteration number:  2940\n",
      "Accuracy =  0.9026488095238095\n",
      "Iteration number:  2960\n",
      "Accuracy =  0.9027083333333333\n",
      "Iteration number:  2980\n",
      "Accuracy =  0.9028869047619048\n",
      "Iteration number:  3000\n",
      "Accuracy =  0.903154761904762\n",
      "Iteration number:  3020\n",
      "Accuracy =  0.9033035714285714\n",
      "Iteration number:  3040\n",
      "Accuracy =  0.903452380952381\n",
      "Iteration number:  3060\n",
      "Accuracy =  0.90375\n",
      "Iteration number:  3080\n",
      "Accuracy =  0.9038690476190476\n",
      "Iteration number:  3100\n",
      "Accuracy =  0.9039285714285714\n",
      "Iteration number:  3120\n",
      "Accuracy =  0.9040178571428571\n",
      "Iteration number:  3140\n",
      "Accuracy =  0.9040476190476191\n",
      "Iteration number:  3160\n",
      "Accuracy =  0.9041369047619048\n",
      "Iteration number:  3180\n",
      "Accuracy =  0.9042857142857142\n",
      "Iteration number:  3200\n",
      "Accuracy =  0.9043452380952381\n",
      "Iteration number:  3220\n",
      "Accuracy =  0.9044642857142857\n",
      "Iteration number:  3240\n",
      "Accuracy =  0.9047321428571429\n",
      "Iteration number:  3260\n",
      "Accuracy =  0.9049107142857142\n",
      "Iteration number:  3280\n",
      "Accuracy =  0.9050892857142857\n",
      "Iteration number:  3300\n",
      "Accuracy =  0.9051488095238095\n",
      "Iteration number:  3320\n",
      "Accuracy =  0.9052083333333333\n",
      "Iteration number:  3340\n",
      "Accuracy =  0.9053571428571429\n",
      "Iteration number:  3360\n",
      "Accuracy =  0.9055654761904762\n",
      "Iteration number:  3380\n",
      "Accuracy =  0.9056547619047619\n",
      "Iteration number:  3400\n",
      "Accuracy =  0.9057738095238095\n",
      "Iteration number:  3420\n",
      "Accuracy =  0.9057738095238095\n",
      "Iteration number:  3440\n",
      "Accuracy =  0.9058928571428572\n",
      "Iteration number:  3460\n",
      "Accuracy =  0.905952380952381\n",
      "Iteration number:  3480\n",
      "Accuracy =  0.9060714285714285\n",
      "Iteration number:  3500\n",
      "Accuracy =  0.9060714285714285\n",
      "Iteration number:  3520\n",
      "Accuracy =  0.90625\n",
      "Iteration number:  3540\n",
      "Accuracy =  0.9064583333333334\n",
      "Iteration number:  3560\n",
      "Accuracy =  0.9064583333333334\n",
      "Iteration number:  3580\n",
      "Accuracy =  0.9065178571428572\n",
      "Iteration number:  3600\n",
      "Accuracy =  0.906547619047619\n",
      "Iteration number:  3620\n",
      "Accuracy =  0.9065773809523809\n",
      "Iteration number:  3640\n",
      "Accuracy =  0.9067261904761905\n",
      "Iteration number:  3660\n",
      "Accuracy =  0.9069345238095238\n",
      "Iteration number:  3680\n",
      "Accuracy =  0.9072023809523809\n",
      "Iteration number:  3700\n",
      "Accuracy =  0.9073214285714286\n",
      "Iteration number:  3720\n",
      "Accuracy =  0.9074404761904762\n",
      "Iteration number:  3740\n",
      "Accuracy =  0.9075297619047619\n",
      "Iteration number:  3760\n",
      "Accuracy =  0.9076488095238096\n",
      "Iteration number:  3780\n",
      "Accuracy =  0.9078571428571428\n",
      "Iteration number:  3800\n",
      "Accuracy =  0.9080059523809524\n",
      "Iteration number:  3820\n",
      "Accuracy =  0.908125\n",
      "Iteration number:  3840\n",
      "Accuracy =  0.9082738095238095\n",
      "Iteration number:  3860\n",
      "Accuracy =  0.9085119047619048\n",
      "Iteration number:  3880\n",
      "Accuracy =  0.9086011904761905\n",
      "Iteration number:  3900\n",
      "Accuracy =  0.9088392857142857\n",
      "Iteration number:  3920\n",
      "Accuracy =  0.9089880952380952\n",
      "Iteration number:  3940\n",
      "Accuracy =  0.9092559523809524\n",
      "Iteration number:  3960\n",
      "Accuracy =  0.9092261904761905\n",
      "Iteration number:  3980\n",
      "Accuracy =  0.9094345238095238\n",
      "Iteration number:  4000\n",
      "Accuracy =  0.9095535714285714\n",
      "Iteration number:  4020\n",
      "Accuracy =  0.9098214285714286\n",
      "Iteration number:  4040\n",
      "Accuracy =  0.9098511904761905\n",
      "Iteration number:  4060\n",
      "Accuracy =  0.9099107142857142\n",
      "Iteration number:  4080\n",
      "Accuracy =  0.9098511904761905\n",
      "Iteration number:  4100\n",
      "Accuracy =  0.9099404761904762\n",
      "Iteration number:  4120\n",
      "Accuracy =  0.9101488095238095\n",
      "Iteration number:  4140\n",
      "Accuracy =  0.9102380952380953\n",
      "Iteration number:  4160\n",
      "Accuracy =  0.9102976190476191\n",
      "Iteration number:  4180\n",
      "Accuracy =  0.9102678571428572\n",
      "Iteration number:  4200\n",
      "Accuracy =  0.9102678571428572\n",
      "Iteration number:  4220\n",
      "Accuracy =  0.9103571428571429\n",
      "Iteration number:  4240\n",
      "Accuracy =  0.910327380952381\n",
      "Iteration number:  4260\n",
      "Accuracy =  0.9103869047619048\n",
      "Iteration number:  4280\n",
      "Accuracy =  0.9105357142857143\n",
      "Iteration number:  4300\n",
      "Accuracy =  0.9106845238095238\n",
      "Iteration number:  4320\n",
      "Accuracy =  0.9108928571428572\n",
      "Iteration number:  4340\n",
      "Accuracy =  0.9109821428571429\n",
      "Iteration number:  4360\n",
      "Accuracy =  0.9110119047619047\n",
      "Iteration number:  4380\n",
      "Accuracy =  0.9110714285714285\n",
      "Iteration number:  4400\n",
      "Accuracy =  0.9111904761904762\n",
      "Iteration number:  4420\n",
      "Accuracy =  0.91125\n",
      "Iteration number:  4440\n",
      "Accuracy =  0.9113095238095238\n",
      "Iteration number:  4460\n",
      "Accuracy =  0.9114285714285715\n",
      "Iteration number:  4480\n",
      "Accuracy =  0.9114583333333334\n",
      "Iteration number:  4500\n",
      "Accuracy =  0.911577380952381\n",
      "Iteration number:  4520\n",
      "Accuracy =  0.911577380952381\n",
      "Iteration number:  4540\n",
      "Accuracy =  0.911577380952381\n",
      "Iteration number:  4560\n",
      "Accuracy =  0.9116666666666666\n",
      "Iteration number:  4580\n",
      "Accuracy =  0.9117857142857143\n",
      "Iteration number:  4600\n",
      "Accuracy =  0.9119642857142857\n",
      "Iteration number:  4620\n",
      "Accuracy =  0.9119940476190476\n",
      "Iteration number:  4640\n",
      "Accuracy =  0.9121428571428571\n",
      "Iteration number:  4660\n",
      "Accuracy =  0.9123214285714286\n",
      "Iteration number:  4680\n",
      "Accuracy =  0.9124107142857143\n",
      "Iteration number:  4700\n",
      "Accuracy =  0.9125\n",
      "Iteration number:  4720\n",
      "Accuracy =  0.9127083333333333\n",
      "Iteration number:  4740\n",
      "Accuracy =  0.912797619047619\n",
      "Iteration number:  4760\n",
      "Accuracy =  0.9128273809523809\n",
      "Iteration number:  4780\n",
      "Accuracy =  0.9129464285714286\n",
      "Iteration number:  4800\n",
      "Accuracy =  0.9129464285714286\n",
      "Iteration number:  4820\n",
      "Accuracy =  0.9130654761904762\n",
      "Iteration number:  4840\n",
      "Accuracy =  0.9132142857142858\n",
      "Iteration number:  4860\n",
      "Accuracy =  0.9132142857142858\n",
      "Iteration number:  4880\n",
      "Accuracy =  0.913125\n",
      "Iteration number:  4900\n",
      "Accuracy =  0.9132142857142858\n",
      "Iteration number:  4920\n",
      "Accuracy =  0.9133333333333333\n",
      "Iteration number:  4940\n",
      "Accuracy =  0.9134821428571429\n",
      "Iteration number:  4960\n",
      "Accuracy =  0.9135714285714286\n",
      "Iteration number:  4980\n",
      "Accuracy =  0.9136904761904762\n"
     ]
    }
   ],
   "source": [
    "W1,B1,W2,B2=gradient_descent(X_train,Y_train,0.10,5000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [9]\n",
      "Actual:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data=0\n",
    "\n",
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val[:, val_data, None])\n",
    "\n",
    "print(\"Prediction: \", get_predictions(a2_val))\n",
    "print(\"Actual: \", Y_val[val_data])\n",
    "\n",
    "image_array= X_val[:, val_data].reshape(28, 28)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_val, a1_val, z2_val, a2_val = forward_propagation(W1, B1, W2, B2, X_val)\n",
    "\n",
    "val_acc=get_accuracy(get_predictions(a2_val), Y_val)\n",
    "print(\"Validation accuracy: \", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
